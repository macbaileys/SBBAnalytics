{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model Evaluation: Regression & Classification\n",
                "\n",
                "This notebook demonstrates **model evaluation** on a dataset of Swiss train stations, covering two scenarios:\n",
                "1. **Regression** (predicting a numeric target, e.g., `DTV`)\n",
                "2. **Classification** (predicting a binary label, e.g., High vs. Low traffic)\n",
                "\n",
                "We will use **scikit-learn** metrics:\n",
                "- **Regression**: R², MAE, RMSE\n",
                "- **Classification**: Accuracy, Precision, Recall, F1, Confusion Matrix\n",
                "\n",
                "## Contents\n",
                "1. **Setup** (imports)\n",
                "2. **Data Loading & Preparation**\n",
                "3. **Regression** Example\n",
                "4. **Classification** Example\n",
                "5. **Summary & Next Steps**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "collapsed": false
            },
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'sklearn'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn [1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression, LogisticRegression\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     r2_score, mean_absolute_error, mean_squared_error,\n\u001b[0;32m     11\u001b[0m     accuracy_score, precision_score, recall_score, f1_score,\n\u001b[0;32m     12\u001b[0m     confusion_matrix\n\u001b[0;32m     13\u001b[0m )\n",
                        "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
                    ]
                }
            ],
            "source": [
                "# 1) Setup\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
                "from sklearn.metrics import (\n",
                "    r2_score, mean_absolute_error, mean_squared_error,\n",
                "    accuracy_score, precision_score, recall_score, f1_score,\n",
                "    confusion_matrix\n",
                ")\n",
                "\n",
                "# Optional: for inline plotting in Jupyter\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Loading & Preparation\n",
                "We assume you have a CSV named `stations.csv` containing columns like:\n",
                "- `DTV`, `DWV`, `DNWV` (numeric)\n",
                "- `Kanton`, `EVU` (categorical)\n",
                "- `lon`, `lat` (numeric)\n",
                "… and more.\n",
                "\n",
                "### 2.1 Load Data & Basic Cleaning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load your CSV file\n",
                "df = pd.read_csv(\"stations.csv\")  # change if needed\n",
                "print(\"Data shape:\", df.shape)\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Drop Missing or Invalid Rows\n",
                "We'll keep only rows where `DTV`, `DWV`, `DNWV`, `Kanton`, `EVU`, `lon`, `lat` are valid."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "required_cols = ['DTV','DWV','DNWV','Kanton','EVU','lon','lat']\n",
                "df.dropna(subset=required_cols, inplace=True)\n",
                "\n",
                "# Convert numeric columns\n",
                "num_cols = ['DTV','DWV','DNWV','lon','lat']\n",
                "for c in num_cols:\n",
                "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
                "\n",
                "df.dropna(subset=num_cols, inplace=True)\n",
                "print(\"Data shape after cleaning:\", df.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3 Encode Categorical Features\n",
                "We do one-hot encoding for `Kanton` and `EVU` so we can use them in scikit-learn."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_encoded = pd.get_dummies(df, columns=['Kanton','EVU'], drop_first=True)\n",
                "print(\"Encoded shape:\", df_encoded.shape)\n",
                "df_encoded.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Regression Example\n",
                "We’ll predict the **numeric** target `DTV` from the available features. For simplicity, we’ll consider:\n",
                "- `DWV`, `DNWV`, `lon`, `lat` + one-hot columns for `Kanton` and `EVU`\n",
                "\n",
                "### 3.1 Train/Test Split\n",
                "We'll do a standard 80/20 split."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "target_col = 'DTV'\n",
                "exclude_cols = ['Code','UIC','Bahnhof','ISB_GI','Jahr','DTV']\n",
                "\n",
                "X_cols = [c for c in df_encoded.columns if c not in exclude_cols]\n",
                "X = df_encoded[X_cols].values\n",
                "y = df_encoded[target_col].values\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "print(\"Train set shape:\", X_train.shape, y_train.shape)\n",
                "print(\"Test  set shape:\", X_test.shape,  y_test.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Fit a Linear Regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "reg_model = LinearRegression()\n",
                "reg_model.fit(X_train, y_train)\n",
                "\n",
                "y_pred = reg_model.predict(X_test)\n",
                "print(\"Model trained.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.3 Evaluate Regression\n",
                "- **R²** (coefficient of determination)\n",
                "- **MAE** (mean absolute error)\n",
                "- **RMSE** (root mean squared error)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "r2 = r2_score(y_test, y_pred)\n",
                "mae = mean_absolute_error(y_test, y_pred)\n",
                "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
                "\n",
                "print(\"Regression Metrics:\")\n",
                "print(f\"  R^2   = {r2:.3f}\")\n",
                "print(f\"  MAE   = {mae:.2f}\")\n",
                "print(f\"  RMSE  = {rmse:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.4 Visualize Predicted vs Actual"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(6,6))\n",
                "plt.scatter(y_test, y_pred, alpha=0.5)\n",
                "plt.plot([0, max(y_test)], [0, max(y_test)], '--r')\n",
                "plt.title(\"Predicted vs. Actual DTV\")\n",
                "plt.xlabel(\"Actual DTV\")\n",
                "plt.ylabel(\"Predicted DTV\")\n",
                "plt.xlim([0, max(y_test)*1.1])\n",
                "plt.ylim([0, max(y_pred)*1.1])\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Classification Example\n",
                "We'll create a **binary** target for “High Traffic” vs “Low Traffic,” e.g. stations with `DTV >= 1000` are **1** (high) else **0** (low).\n",
                "\n",
                "Then we use **Logistic Regression** (as a simple classifier) and evaluate with:\n",
                "- Accuracy\n",
                "- Precision\n",
                "- Recall\n",
                "- F1 score\n",
                "- Confusion matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create binary target\n",
                "df_encoded['HighTraffic'] = (df_encoded['DTV'] >= 1000).astype(int)\n",
                "\n",
                "# We'll predict HighTraffic from the same set of features,\n",
                "# but exclude DTV itself.\n",
                "exclude_cols_clf = ['HighTraffic','DTV','Code','UIC','Bahnhof','ISB_GI','Jahr']\n",
                "X_cols_clf = [c for c in df_encoded.columns if c not in exclude_cols_clf]\n",
                "X_clf = df_encoded[X_cols_clf].values\n",
                "y_clf = df_encoded['HighTraffic'].values\n",
                "\n",
                "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
                "    X_clf, y_clf, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "clf_model = LogisticRegression(max_iter=1000)\n",
                "clf_model.fit(X_train_clf, y_train_clf)\n",
                "\n",
                "# Predict on test set\n",
                "y_pred_clf = clf_model.predict(X_test_clf)\n",
                "\n",
                "print(\"Classification model trained.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.1 Evaluate Classification\n",
                "- **Accuracy**: overall fraction of correct predictions\n",
                "- **Precision**: fraction of predicted positives that are correct\n",
                "- **Recall**: fraction of actual positives that are identified\n",
                "- **F1**: harmonic mean of precision and recall\n",
                "\n",
                "Finally, we plot the **confusion matrix** as a heatmap."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "acc = accuracy_score(y_test_clf, y_pred_clf)\n",
                "prec = precision_score(y_test_clf, y_pred_clf, zero_division=0)\n",
                "rec = recall_score(y_test_clf, y_pred_clf, zero_division=0)\n",
                "f1 = f1_score(y_test_clf, y_pred_clf, zero_division=0)\n",
                "\n",
                "print(\"Classification Metrics:\")\n",
                "print(f\"  Accuracy  = {acc:.3f}\")\n",
                "print(f\"  Precision = {prec:.3f}\")\n",
                "print(f\"  Recall    = {rec:.3f}\")\n",
                "print(f\"  F1 Score  = {f1:.3f}\")\n",
                "\n",
                "cm = confusion_matrix(y_test_clf, y_pred_clf)\n",
                "print(\"\\nConfusion Matrix:\")\n",
                "print(cm)\n",
                "\n",
                "plt.figure(figsize=(5,4))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
                "plt.title(\"Confusion Matrix (HighTraffic vs. LowTraffic)\")\n",
                "plt.xlabel(\"Predicted\")\n",
                "plt.ylabel(\"Actual\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Summary & Next Steps\n",
                "\n",
                "1. **Regression**\n",
                "   - We used **LinearRegression** to predict `DTV`.\n",
                "   - Evaluated with **R²**, **MAE**, **RMSE**, and a scatter plot.\n",
                "\n",
                "2. **Classification**\n",
                "   - We defined a binary label `HighTraffic`.\n",
                "   - Used **LogisticRegression** to classify stations.\n",
                "   - Evaluated with **accuracy**, **precision**, **recall**, **F1**, and a confusion matrix.\n",
                "\n",
                "### Possible Enhancements\n",
                "- **Cross-validation**: More robust performance estimates.\n",
                "- **Hyperparameter tuning**: `GridSearchCV` or `RandomizedSearchCV`.\n",
                "- **Alternative models**: Random Forest, Gradient Boosting, etc.\n",
                "- **Feature engineering**: More meaningful transformations of `DWV`, `DNWV`, location-based features, etc.\n",
                "- **Handling skew**: Log-transform `DTV` or set thresholds carefully.\n",
                "\n",
                "This completes our **model evaluation** demo!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
